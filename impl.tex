\chapter{Implementation} % (fold)
\label{cha:impl}
	As the given tasks are all related to optimising the GPS acquisition, we start with the actual algorithm and how it can be changed to perform better. The second major topic is the CGRA and which compositions perform best for maximum performance and minimal energy consumption. Finally, the results of the applied optimisations are discussed and set into relation with the given tasks.

	\section{Algorithm} % (fold)
	\label{sec:impl_algorithmic_changes}
		The process of optimisation is generally a very iterative one, even more so in face of different algorithmic possibilities which we were exploring in the course of this work. It is the purpose of this section to show the different approaches taken and why they have been dismissed or approved for solving the given tasks.

		\subsection{Initial Algorithm} % (fold)
		\label{sub:initial_algorithm}
			Section [\ref{sec:task_algorithm}] explains the algorithm given with the task description. It was implemented as the very first solution for the given tasks and served mainly for getting to know the framework and having a basis to work from. It excelled in this domain but showed very quickly that it is not a feasible solution for the given tasks as it is too slow with clock cycle counts well over \num{100} million. 
		% subsection initial_algorithm (end)

		\subsection{Changes to the Initial Algorithm} % (fold)
		\label{sub:changes_to_the_initial_algorithm}
			As described in section [\ref{sec:task_algorithm}], we are able to use frequency domain multiplication of the the locally available code samples and the received samples. However, the DFT runtime is in $O(n^2)$, where n is the amount of samples in the local code we are trying to match to the received signal. In this case, it is very interesting to reduce the amount of DFT calculations.\\
			In the original algorithm it is assumed that the carrier wipe off is performed in the time domain. As this operation depends on the Doppler-Shift we are currently evaluating, we have to apply the DFT to every time domain signal with different Doppler-Shift frequency carrier wipe off. However, it can be observed that the carrier wipe off is characterising a frequency shift in the time domain. As there is an analogue operation in the frequency domain, it is possible to perform the DFT only once and apply the frequency shift in the frequency domain. Equation [\ref{eq:freq_dom_shift}] shows that this operation is very simple as it only applies a shift to the calculated DFT samples.

			\begin{equation} 
				\label{eq:freq_dom_shift}
				x(n)e^{\frac{j2{\pi}ni}{N}}\quad \laplace\quad X_{DFT}(k-i)_{mod N} % it is stupid, but \laplace yields the symbol I expect when talking about time -> frequency transforms
			\end{equation}

			With 

			\begin{equation} 
				(k-i)_{mod N}\ =\ (k-i)\ modulo\ N
			\end{equation}

			and 

			\begin{equation}
				\label{eq:i_res}
				i\ =\ -\frac{Nf_d}{f_s}
			\end{equation}

			where $N$ is the number of samples, $f_d$ is the currently used Doppler-Frequency and $f_s$ the sampling frequency. Equation [\ref{eq:i_res}] results from the following equation [\ref{eq:i_eq}]. It has to be noted that $i$ is expected to be a whole number.

			\begin{equation} 
				\label{eq:i_eq}
				e^{\frac{-j2{\pi}nf_d}{f_s}} = e^{\frac{j2{\pi}ni}{N}}
			\end{equation}

			Initial tests of this approach showed that it is indeed feasible and performs much better than calculating the DFT for multiple different time domain sample vectors. Unfortunately, it is not possible to use it for each of the given tests as it depends on $i$ being a whole number. In our setup, this is the case for tests which feature \num{400} samples as input. As this approach could never solve one test of the given tests, it was dismissed.
		% subsection changes_to_the_initial_algorithm (end)
		
		\section{Convolution in the Time Domain} % (fold)
		\label{sec:convolution_in_the_time_domain}
	  		As stated above, the method which implies using a frequency shift to the calculated DFT samples is valid only for a certain number of samples. To overcome this issue, another mathematical transformation needs to be taken into consideration. Having the original code as a starting point, the multiplication of the code samples and the received samples in frequency domain is now replaced by their circular convolution in time domain. This second solution is based on the following formula [\ref{eq:circular_conv}]:

			\begin{equation} 
				\label{eq:circular_conv}
				x_{1}(n) \circledast x_{2}(n)\quad \laplace\quad X_{DFT,1}(k)X_{DFT,2}(k)
			\end{equation} 

			Because in frequency domain we had to compute the complex conjugate of the code samples, in time domain the corresponding IDFT is needed in order to correctly calculate the circular convolution. Thus, the DFT of the code samples, its corresponding complex conjugate and its IDFT is computed outside of the loop going through all the frequencies. Inside of the loop, only the circular convolution is required, without transforming the received samples to frequency domain. Because of this, the solution is faster in comparison to the original code.\\
			Using the reversal and conjugation theorems of the DFT, there is no need to compute the transformation of the code samples in frequency domain. Thus, only the loop going through all the frequencies remains. Now, when computing the circular convolution, the term $IDFT(\overline{DFT(code\_samples(k)}))$, can be replaced by $\overline{code\_samples(-n)}$.\\ 
			While optimizing the code, we notice that using conditional statements inside of a loop, decreases the quality of the result. Thus, we try to avoid this construct as much as possible. One such example is when computing the modulo of a difference required for the circular convolution. The terms of the difference are the control variables of two nested loops. The difference could give negative results, which need to be adjusted. Instead of using a conditional clause to check whether the result is positive or not, we break the inner loop into two loops and compute the differnce in such a way that the result will allways be positive.\\
			Additionally, when implementing the code, we used float type variables only in places where they were absolutely required and integer variables in the rest of the code. Integer computations are conducted faster by the PEs in comparison to the floating point ones. 
		% subsection convolution_in_the_time_domain (end)
	% impl_algorithmic_changes (end)
	
		\section{Testing our implementation} % (fold)
	\label{sec:test_impl}
		After implementing the code, we need to test whether it gives feasible results. We run all the six tests for an unroll factor of 12 and using a CGRA configuration with 16 PEs with a regular connection scheme. The code passes all the tests and gives the following results:
		\begin{center}
			\begin{tabular}{||c | c c c ||} 
			\hline
			Test number & Ticks & Energy consumption & Execution Time (ms)\\ [0.5ex] 
			\hline\hline
			1 & 77396741 & 405345641.736 & 185692 \\
			\hline
			2 & 77215522 & 404817134.050 & 320418 \\
			\hline
			3 & 77318793 & 405118151.353 & 300279 \\
			\hline
			4 & 77160483 & 404691683.578 & 307495 \\
			\hline
			5 & 96283305 & 539195938.977 & 289390 \\  
			\hline
			6 & 77839517 & 409169958.157 & 172442 \\  
			\hline
			\end{tabular}
		\end{center}
		
	% section test_impl (end)

	\section{CGRA Changes} % (fold)
	\label{sec:cgra_changes}
		The initially provided CGRA is based on a mesh of \num{16} almost homogeneous PEs. Four of the \num{16} PEs are equipped with memory access operations and live out ports to provide the calculated results to the AMIDAR bus system. All other PEs feature the complete set of available AMIDAR CGRA operations, including some which are never used by our code. The most obviously unused operations are all double precision floating point related and are not present any more in the PEs we are using now. All other operations in the used PEs remain the same.\newline
		
		More changes to the initial composition are observable when looking at the introduced connection scheme. It is obvious that more connections between individual PEs make it easier the schedule a kernel on all of them. In the most extreme case, a regular connection scheme may be applied, which connects each PE to all the others in the given array. This in turn enables each PE to read results from all other PEs which makes it simpler to schedule the given kernel on the array and yields better cycle counts in the end. All of our CGRA compositions are now using the regular connection scheme as it yields the best results when only looking at the resulting clock cycles. However, when taking into account that a real implementation of a regularly interconnected 16 PE CGRA is probably immensely more expensive (chips space and timing related) than an irregularly connected 16 PE CGRA, it has to be noted that only the used evaluation mechanism (counting clock cycles) is enabling us to use such a solution. Real implementations would have to carefully increase the amount of connections per PE while constantly benchmarking the resulting CGRA in the context of actual execution time for a given application.\newline
		
		The amount of PEs used in the array was not increased as no notable gains could be observed. It seems that the upper limit of four memory accessing PEs is responsible for harshly limiting the gains of adding more PEs. 
		However, reducing the amount of PEs from \num{16} to eight brought significant changes in the domain of energy consumption while also preserving some of the speed up of the CGRA execution.
	% section cgra_changes (end)
	



	\section{Testing Several Configurations} % (fold)
	\label{sec:impl_max_perf}
		In order to find the solutions with maximum performance or minimum energy consumption, several configurations and parameters need to be tested. 
		In the first analysis, the unroll factor is seeped. The configuration used implies a 16 PE array with regular connection scheme. The results are shown in the following table:

		\begin{center}
			\begin{tabular}{||c | c c c ||} 
			\hline
			Unroll Factor & Ticks & Energy consumption & Execution Time (ms)\\ [0.5ex] 
			\hline\hline
			6 & 79582066 & 449377273.101 & 215307 \\
			\hline
			8 & 78557499 & 426409740.037 & 179675 \\
			\hline
			10 & 78157745 & 417367066.187 & 189179 \\
			\hline
			12 & 77396741 & 405345641.736 & 185692 \\
			\hline
			14 & 77489539 & 407485036.248 & 177463 \\  
			\hline
			16 & 77839517 & 409169958.157 & 172442 \\  
			\hline
			18 & 77881486 & 413682459.689 & 181371 \\ 
			\hline
			20 & 77600525 & 408564555.489 & 175593 \\  
			\hline
			22 & 77966352 & 415544847.986 & 174937 \\
			\hline
			\end{tabular}
		\end{center}
	  
		The best result is obtained when using an unroll factor of 12. Thus, this unroll factor will be used further on when testing other parameters. \newline
		In the second analysis, several configurations of the CGRA are tested. We start with the already available ones and than modify them by implementing a regular interconnection scheme and removing double operations from the FU. When testing the given configuration for four PEs, the following error occurres: "Not able to synthesize: Context memory is too small. Needed 1098 contexts. Only 256 available". Thus, we increase the context size to 4096. The results are shown in the next table:
  
		\begin{center}
			\begin{tabular}{||c | c c c ||} 
			\hline
			Configuration & Ticks & 	\begin{tabular}{@{}c@{}}Energy \\  Consumption\end{tabular} & 	\begin{tabular}{@{}c@{}}Execution Time\\ (ms)\end{tabular}\\ [0.5ex] 
			\hline\hline
			Config.  4 & 101893082 & 231411757.630 & 210058 \\
			\hline
			Config. 16 & 83764981 & 461260188.769 & 202527 \\
			\hline
			Config. 20 & 83448763 & 563071106.407 & 253477 \\
			\hline
			\begin{tabular}{@{}c@{}}Config.  8 \\  Regular Interconnection\\ No Double Precision \end{tabular} & 80104307 & 217189239.239 & 184179 \\
			\hline
			\begin{tabular}{@{}c@{}}Config.  16 \\  Regular Interconnection\\ No Double Precision \end{tabular} & 77396741 & 405345641.736 & 171574 \\  
			\hline
			\begin{tabular}{@{}c@{}}Config.  24 \\  Regular Interconnection\\ No Double Precision \end{tabular} & 77527500 & 664898600.755 & 285638 \\  
			\hline
			\end{tabular}
		\end{center}
  
	% section impl_max_perf (end)
	\section{Maximum Performance} % (fold)
	\label{sec:impl_max_perf}
		After running several tests, we notice that the solution which yields the best performance is for an unroll factor of 12, while using 16 PEs connected using a regular scheme. The interconnection strategy plays an important role in maximising the performance. However, this comes with higher costs. Additionally, for maximising performance, we avoided using conditional clauses in the code and we used integer variables where allowed. Additionally, we tried to construct the code in such a way that the computations could be run in parallel. We must point out, that when measuring the performance, the ticks number was taken into consideration. However, when using a regular interconnection, it is highly probable that the clock frequency will get lower and thus the overall time will grow. 
	% section impl_max_perf (end)

	\section{Minimum Energy Consumption} % (fold)
	\label{sec:impl_min_energy}
		When measuring the power consumption, the number of PEs used in the CGRA is the main factor that influences the result. To obtain a good energy consumption, we used just 3 PEs. It is unlikely that such a configuration would be useful in practical cases. Additionally, for obtaining a lower energy consumption, the number of operations computed in parallel is reduced. For example, instead of computing four times in parallel the argument of the sinus and cosinus function, we compute it once and store this value as a variable. For this configuration we obtain an energy consumption of: 178839828.424.
	% section impl_min_energy (end)
	
	\section{Integer values for the code samples} % (fold)
	\label{sec:impl_min_energy}
		The values received as code samples are all integer values. Thus if we implement again the function taking into consideration this aspect, the the number of ticks becomes 76348423. An unroll factor of 12 and CGRA configuration with 16 PEs were used. 
	% section impl_min_energy (end)
% chapter impl (end)